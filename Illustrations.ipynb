{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Illustrations.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCqMWUPEueA0zrZpm5ffAE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jzinnegger/differential-ml/blob/main/Illustrations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yq7P--Y7Ov9"
      },
      "source": [
        "## Illustration of pathwise learning with  differentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW57LT8c_d0Q"
      },
      "source": [
        "The notebook illustrates the pathwise learning of the fair value and delta (as a function of the underlying stock price) in the Black Scholes setup. The example is based on the work of Brian Huge and Antoine Savine (see Working paper: https://arxiv.org/abs/2005.02347 and GitHub: https://github.com/differential-machine-learning).\n",
        "\n",
        "The samples of the initial stock price $S_1$ at $T_1$ are drawn from a uniform distribution. In the original example the initial state space at $T_1$ can be seen as a time slice of the (simulated) process starting at $T_0$. The time slice approach is convenient to the derive a consitent state space for a higher dimensional market model where all paths follow the same underlying model and calibration.\n",
        "\n",
        "The twin neural network is indepedently implemented in Keras/Tensorflow2.\n",
        "The implementation of the model is provided in [Github: jzinnegger/differential-ml](https://github.com/jzinnegger/differential-ml/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qg9ulVweOtb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import datetime             \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "tf.keras.backend.set_floatx('float32') # default\n",
        "real_type = tf.float32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITEUvD-hS0Uh"
      },
      "source": [
        "# clone git\n",
        "import os\n",
        "os.chdir(\"/content\")\n",
        "!rm -rf differential-ml\n",
        "!git clone --depth=1 https://github.com/jzinnegger/differential-ml.git\n",
        "os.chdir(\"./differential-ml\")\n",
        "from my_python.models import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CESX6QcJOvA3"
      },
      "source": [
        "### Generate training data of pathwise values and deltas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaujwUKrT2HV"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm  \n",
        "# helper analytics    \n",
        "def bsPrice(spot, strike, vol, T):\n",
        "    d1 = (np.log(spot/strike) + vol * vol * T) / vol / np.sqrt(T)\n",
        "    d2 = d1 - vol * np.sqrt(T)\n",
        "    return spot * norm.cdf(d1) - strike * norm.cdf(d2)\n",
        "\n",
        "def bsDelta(spot, strike, vol, T):\n",
        "    d1 = (np.log(spot/strike) + vol * vol * T) / vol / np.sqrt(T)\n",
        "    return norm.cdf(d1)\n",
        "\n",
        "def bsVega(spot, strike, vol, T):\n",
        "    d1 = (np.log(spot/strike) + vol * vol * T) / vol / np.sqrt(T)\n",
        "    return spot * np.sqrt(T) * norm.pdf(d1)\n",
        "#\n",
        "    \n",
        "# main class\n",
        "class BlackScholes:\n",
        "    \n",
        "    def __init__(self, \n",
        "                 vol=0.2,\n",
        "                 T1=1, \n",
        "                 T2=2, \n",
        "                 K=1.10,\n",
        "                 volMult=1.5,\n",
        "                 lower=0.35,\n",
        "                 upper=1.65):\n",
        "        \n",
        "        self.spot = 1\n",
        "        self.vol = vol\n",
        "        self.T1 = T1\n",
        "        self.T2 = T2\n",
        "        self.K = K\n",
        "        self.volMult = volMult\n",
        "                        \n",
        "    # training set: returns S1 (mx1), C2 (mx1) and dC2/dS1 (mx1)\n",
        "    def trainingSet(self, m,  anti=True, seed=None):\n",
        "    \n",
        "        np.random.seed(seed)\n",
        "        \n",
        "        # 2 sets of normal returns\n",
        "        returns = np.random.normal(size=[m, 2])\n",
        "\n",
        "        # SDE\n",
        "        vol0 = self.vol * self.volMult\n",
        "        R1 = np.exp(-0.5*vol0*vol0*self.T1 + vol0*np.sqrt(self.T1)*returns[:,0])\n",
        "\n",
        "        R2 = np.exp(-0.5*self.vol*self.vol*(self.T2-self.T1) \\\n",
        "                    + self.vol*np.sqrt(self.T2-self.T1)*returns[:,1])\n",
        "        S1 = self.spot * R1\n",
        "        S2 = S1 * R2 \n",
        "\n",
        "        # payoff\n",
        "        pay = np.maximum(0, S2 - self.K)\n",
        "        \n",
        "        # two antithetic paths\n",
        "        if anti:\n",
        "            \n",
        "            R2a = np.exp(-0.5*self.vol*self.vol*(self.T2-self.T1) \\\n",
        "                    - self.vol*np.sqrt(self.T2-self.T1)*returns[:,1])\n",
        "            S2a = S1 * R2a             \n",
        "            paya = np.maximum(0, S2a - self.K)\n",
        "            \n",
        "            X = S1\n",
        "            Y = 0.5 * (pay + paya)\n",
        "    \n",
        "            # differentials\n",
        "            Z1 =  np.where(S2 > self.K, R2, 0.0).reshape((-1,1)) \n",
        "            Z2 =  np.where(S2a > self.K, R2a, 0.0).reshape((-1,1)) \n",
        "            Z = 0.5 * (Z1 + Z2)\n",
        "                    \n",
        "        # standard\n",
        "        else:\n",
        "        \n",
        "            X = S1\n",
        "            Y = pay\n",
        "            \n",
        "            # differentials\n",
        "            Z =  np.where(S2 > self.K, R2, 0.0).reshape((-1,1)) \n",
        "        \n",
        "        return X.reshape([-1,1]), Y.reshape([-1,1]), Z.reshape([-1,1])\n",
        "    \n",
        "    def trainingSetUniformS1(self, m, lower=0.2, upper=2.0, anti=True, seed=None):\n",
        "\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # 1 set of uniform samples in the one-dim parameter space for S1=S1(R1)\n",
        "        S1 = np.random.uniform(lower,upper,m) * self.spot\n",
        "        \n",
        "        # 2 sets of normal returns, only R2 required\n",
        "        returns = np.random.normal(size=[m, 1])\n",
        "\n",
        "        # SDE\n",
        "        R2 = np.exp(-0.5*self.vol*self.vol*(self.T2-self.T1) \\\n",
        "                    + self.vol*np.sqrt(self.T2-self.T1)*returns[:,0])\n",
        "        # S1 = self.spot * R1\n",
        "        S2 = S1 * R2 \n",
        "\n",
        "        # payoff\n",
        "        pay = np.maximum(0, S2 - self.K)\n",
        "        \n",
        "        # two antithetic paths\n",
        "        if anti:\n",
        "            \n",
        "            R2a = np.exp(-0.5*self.vol*self.vol*(self.T2-self.T1) \\\n",
        "                    - self.vol*np.sqrt(self.T2-self.T1)*returns[:,0])\n",
        "            S2a = S1 * R2a             \n",
        "            paya = np.maximum(0, S2a - self.K)\n",
        "            \n",
        "            X = S1\n",
        "            Y = 0.5 * (pay + paya)\n",
        "    \n",
        "            # differentials\n",
        "            Z1 =  np.where(S2 > self.K, R2, 0.0).reshape((-1,1)) \n",
        "            Z2 =  np.where(S2a > self.K, R2a, 0.0).reshape((-1,1)) \n",
        "            Z = 0.5 * (Z1 + Z2)\n",
        "                    \n",
        "        # standard\n",
        "        else:\n",
        "        \n",
        "            X = S1\n",
        "            Y = pay\n",
        "            \n",
        "            # differentials\n",
        "            Z =  np.where(S2 > self.K, R2, 0.0).reshape((-1,1)) \n",
        "        \n",
        "        return X.reshape([-1,1]), Y.reshape([-1,1]), Z.reshape([-1,1])\n",
        "\n",
        "    # test set: returns a grid of uniform spots \n",
        "    # with corresponding ground true prices, deltas and vegas\n",
        "    def testSet(self, lower=0.35, upper=1.65, num=100, seed=None):\n",
        "        \n",
        "        spots = np.linspace(lower, upper, num).reshape((-1, 1))\n",
        "        # compute prices, deltas and vegas\n",
        "        prices = bsPrice(spots, self.K, self.vol, self.T2 - self.T1).reshape((-1, 1))\n",
        "        deltas = bsDelta(spots, self.K, self.vol, self.T2 - self.T1).reshape((-1, 1))\n",
        "        vegas = bsVega(spots, self.K, self.vol, self.T2 - self.T1).reshape((-1, 1))\n",
        "        return spots, spots, prices, deltas, vegas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz84ENvl6n8v"
      },
      "source": [
        "### Training values and deltas jointly with the twin network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqqtwMgG1-43"
      },
      "source": [
        "Equal weighting of values and differentials in the training (alpha = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfxjnhoq5iAl"
      },
      "source": [
        "weightSeed = np.random.randint(0, 10000)\n",
        "log_dir = \"tensorboard_logs/\"\n",
        "#!mkdir {log_dir}f\"illu_bs\"\n",
        "nTest = 4096\n",
        "sizes = [4096, 4096*2, 4096*4]  \n",
        "generator = BlackScholes()\n",
        "x_train, y_train, dydx_train = generator.trainingSetUniformS1(max(sizes), seed=None, anti=False)\n",
        "x_true, x_axis, y_true, dydx_true, vegas = generator.testSet(num=nTest, lower = 0.2, upper=2.0, seed=None)\n",
        "size=sizes[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg2KUGk39imO"
      },
      "source": [
        "prep_layer, scaled_MSE =  preprocess_data(x_train, y_train, dydx_train, prep_type='Normalisation')\n",
        "model = build_and_compile_model(prep_layer.output_n(),\n",
        "                                    get_model_autodiff,\n",
        "                                    scaled_MSE, \n",
        "                                    lr_schedule = lr_inv_time_decay,  #  lr_warmup, lr_inv_time_decay\n",
        "                                    alpha = 0.5\n",
        "                                )\n",
        "history = train_model(model,\n",
        "                        prep_layer,\n",
        "                        f\"illu_bs\", \n",
        "                        x_train[0:size,:], \n",
        "                        y_train[0:size,:], \n",
        "                        dydx_train[0:size,:], \n",
        "                        epochs=EPOCHS,\n",
        "                        x_true = x_true, \n",
        "                        y_true = y_true, \n",
        "                        dydx_true = dydx_true) \n",
        "y_pred, dydx_pred = predict_unscaled(model, prep_layer, x_true)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tyxZoqo6sTe"
      },
      "source": [
        "### Illustration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGfjhPEl4MGg"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, sharex='row',  figsize=(18,7), squeeze=False)\n",
        "sample_path = 300\n",
        "# Fair value\n",
        "ax[0,0].plot(x_train * 100, y_train, 'c.', markersize=1.5, markerfacecolor='white', label='Training data: Pathwise values')\n",
        "ax[0,0].plot(x_axis*100, y_pred, 'b.', markersize=0.5, markerfacecolor='white', label='Prediction: Expected values')\n",
        "ax[0,0].plot(x_train[sample_path] * 100, y_train[sample_path], 'ro', markersize=7, markerfacecolor='r', label=f\"Training data: Path {sample_path:d}\")\n",
        "# ax[0,0].plot(x_axis*100, y_true, 'r.', markersize=0.5, markerfacecolor='white', label='True values')\n",
        "\n",
        "#ax[0,0].set_xlim(0.60*100, 1.65*100)\n",
        "ax[0,0].set_ylim(-0.01, 0.6)\n",
        "ax[0,0].set_title(\"Fair value\")\n",
        "ax[0,0].legend(loc='upper left')\n",
        "ax[0,0].set_xlabel('Initial stock price at $T_1$')\n",
        "# Deltas\n",
        "deltidx=0\n",
        "ax[0,1].plot(x_train * 100, dydx_train[:,deltidx], 'c.', markersize=1.5, markerfacecolor='white', label='Training data: Pathwise deltas')\n",
        "ax[0,1].plot(x_axis*100, dydx_pred[:,deltidx], 'b.', markersize=0.5, markerfacecolor='white', label='Prediction: Expected deltas')\n",
        "ax[0,1].plot(x_train[sample_path] * 100, dydx_train[sample_path,deltidx], 'ro', markersize=7,  markerfacecolor='r', label=f\"Training data: Path {sample_path:d}\")\n",
        "# ax[0,1].plot(x_axis*100, dydx_true[:,deltidx], 'r.', markersize=0.5, markerfacecolor='white', label='True deltas')\n",
        "ax[0,1].set_ylim(-0.05, 2)\n",
        "ax[0,1].set_title(\"Delta\")\n",
        "ax[0,1].legend(loc='upper left')\n",
        "ax[0,1].set_xlabel('Initial stock price at $T_1$')\n",
        "plt.xlim(0.6*100, 1.65*100)\n",
        "plt.savefig('illustration_1.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXDb7rayzUJ0"
      },
      "source": [
        "### Train net on values only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ8pS1r32WUR"
      },
      "source": [
        "Alpha = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g26Bis6pzKnb"
      },
      "source": [
        "prep_layer, scaled_MSE =  preprocess_data(x_train, y_train, dydx_train, prep_type='NoNormalisation')\n",
        "model = build_and_compile_model(prep_layer.output_n(),\n",
        "                                    get_model_autodiff,\n",
        "                                    scaled_MSE, \n",
        "                                    lr_schedule = lr_inv_time_decay,  #  lr_warmup, lr_inv_time_decay\n",
        "                                    alpha = 1)\n",
        "history = train_model(model,\n",
        "                        prep_layer,\n",
        "                        f\"illu_bs\", \n",
        "                        x_train[0:size,:], \n",
        "                        y_train[0:size,:], \n",
        "                        dydx_train[0:size,:], \n",
        "                        epochs=EPOCHS,\n",
        "                        x_true = x_true, \n",
        "                        y_true = y_true, \n",
        "                        dydx_true = dydx_true) \n",
        "y_pred, dydx_pred = predict_unscaled(model, prep_layer, x_true)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUzWJYqqzx2q"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, sharex='row',  figsize=(18,7), squeeze=False)\n",
        "# Fair value\n",
        "ax[0,0].plot(x_train * 100, y_train, 'c.', markersize=1.5, markerfacecolor='white', label='Training data: Pathwise values')\n",
        "ax[0,0].plot(x_axis*100, y_pred, 'b.', markersize=0.5, markerfacecolor='white', label='Prediction: Expected values')\n",
        "ax[0,0].plot(x_train[sample_path] * 100, y_train[sample_path], 'ro', markersize=7, markerfacecolor='r', label=f\"Training data: Path {sample_path:d}\")\n",
        "# ax[0,0].plot(x_axis*100, y_true, 'r.', markersize=0.5, markerfacecolor='white', label='True values')\n",
        "\n",
        "#ax[0,0].set_xlim(0.60*100, 1.65*100)\n",
        "ax[0,0].set_ylim(-0.01, 0.6)\n",
        "ax[0,0].set_title(\"Fair value\")\n",
        "ax[0,0].legend(loc='upper left')\n",
        "ax[0,0].set_xlabel('Initial stock price at $T_1$')\n",
        "# Deltas\n",
        "deltidx=0\n",
        "# ax[0,1].plot(x_train * 100, dydx_train[:,deltidx], 'c.', markersize=1.5, markerfacecolor='white', label='Training data: Pathwise deltas')\n",
        "ax[0,1].plot(x_axis*100, dydx_pred[:,deltidx], 'b.', markersize=0.5, markerfacecolor='white', label='Prediction: Expected deltas')\n",
        "# ax[0,1].plot(x_axis*100, dydx_true[:,deltidx], 'r.', markersize=0.5, markerfacecolor='white', label='True deltas')\n",
        "ax[0,1].set_ylim(-0.05, 2)\n",
        "ax[0,1].set_title(\"Delta\")\n",
        "ax[0,1].legend(loc='upper left')\n",
        "ax[0,1].set_xlabel('Initial stock price at $T_1$')\n",
        "plt.xlim(0.6*100, 1.65*100)\n",
        "plt.savefig('illustration_2.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Y78Q81uNgz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}